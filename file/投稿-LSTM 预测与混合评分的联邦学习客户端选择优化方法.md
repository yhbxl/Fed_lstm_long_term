# LSTM 预测与混合评分的联邦学习客户端选择优化方法

张三<sup>1a</sup>，李 四<sup>2</sup>，赵大伟<sup>1b</sup>，刘小虎<sup>1c</sup>



（1．海军航空工程学院 a．院务部；b．新装备培训中心；c．七系，山东 烟台 264001；2．海军装备部，北京 100071）



**摘要**： 传统的联邦学习（Federated Learning）采用随机客户端选择策略，未能充分考虑客户端性能差异和数据分布异构性对系统整体性能的影响。本文提出一种融合性能与数据多样性的客户端选择方法 ——FedLSTM-Sel，综合考虑客户端的历史训练性能与数据多样性，构建混合评分机制，并通过 LSTM 模型预测客户端的未来表现，从而实现前瞻性的选择决策。该方法显著优化了系统的收敛速度、模型精度与通信开销。实验证明，在非独立同分布（Non-IID）环境下，该方法较 FedAvg 提高了 35% 的收敛速度，提升了 7.2% 的模型精度，并减少了 52% 的通信成本，为资源受限场景下的联邦学习提供了有效解决方案。



**关键词**：联邦学习；客户端选择；LSTM；混合策略；性能优化



**中图分类号**：O441.3 **文献标志码**：A

## 0 引言

随着数据隐私保护需求的增强以及边缘计算的发展，联邦学习（Federated Learning, FL）作为一种在不共享原始数据的前提下进行分布式训练的机器学习范式，正逐渐在智能手机、可穿戴设备、医疗影像、交通系统等多个实际场景中得到广泛应用 [1]。它允许成千上万的边缘设备利用本地数据共同训练共享模型，从而在保障隐私的同时提升模型性能 [2]。



尽管联邦学习具备分布式协同和隐私保护等优势，但其在实际部署中仍面临诸多挑战，尤其是客户端选择问题。由于设备间在数据分布、计算能力、通信带宽等方面存在显著异构性，若采用随机或静态的客户端选择策略，可能导致模型训练缓慢、性能不稳定甚至偏倚加剧 [3]。已有研究表明，客户端选择策略在提升模型收敛速度、系统效率和模型泛化性能方面具有显著影响 [4]。



目前大多数客户端选择策略主要依据当前训练轮次中的局部性能指标，如训练精度、梯度变化或通信延迟。然而，现实环境中的客户端性能具有明显的时间波动性和长期趋势特征，单轮指标难以准确反映其未来性能，从而降低了系统整体效率与鲁棒性 [5]。



为应对上述问题，本文提出一种基于历史表现的客户端选择优化方法。我们设计了一种滑动窗口机制，记录客户端多轮训练精度序列，并引入长短期记忆网络（LSTM）对客户端未来训练表现进行预测，作为智能选择的参考依据。进一步，我们融合客户端的预测性能得分与数据多样性指标，构建混合评分机制，实现具有稳定性和泛化能力的客户端选择方案。

## 1 系统工作原理

### 1.1 系统架构

图 1 展示了 FedLSTM-Sel 的架构，旨在在动态异构环境下通过客户端历史训练表现实现前瞻性的选择决策。其核心机制是在固定窗口内累积客户端的训练精度、通信延迟和多样性指标，冻结客户端选择，并通过 LSTM 模型预测其未来训练性能。



![图 1 系统架构图](Fig.1 Fused image of the source images)



在每个窗口内，服务器记录每个客户端的训练精度序列 \(\text{Acc}^1_i, \dots, \text{Acc}^W_i\)、通信延迟 \(T^{\text{comm}}_i\)，以及基于精度方差近似的多样性指标 \(\text{Var}(\text{Acc}^1_i, \dots, \text{Acc}^W_i)\)，计算平均效用：\(\overline{U}_i = \alpha \cdot \text{mean}(\text{Acc}^1_i, \dots, \text{Acc}^W_i) + (1-\alpha) \cdot \text{Var}(\text{Acc}^1_i, \dots, \text{Acc}^W_i) \cdot \beta\)



窗口结束后，冻结的客户端集合进入 LSTM 预测阶段，模型以历史精度序列为输入，输出未来训练精度 \(\hat{\text{Acc}}_i\)。服务器将历史效用与预测值融合，生成评分：\(S_i = \lambda \cdot \overline{U}_i + (1-\lambda) \cdot \hat{\text{Acc}}_i\)



并结合通信延迟进行调节：引入动态奖惩因子 \(\gamma_i\)：



- 当通信延迟低时（\(T^{\text{comm}}_i < T_{\text{thr}}\)），奖励因子 \(\gamma_i = 1 + \delta\)；
- 当通信延迟高时（\(T^{\text{comm}}_i > T_{\text{thr}}\)），惩罚因子 \(\gamma_i = 1 - \delta\)。 最终评分修正为：\(S'_i = S_i \cdot \gamma_i\) 服务器依据评分选择客户端进入下一训练窗口。



**表 1 RMSE 平均比较** Tab.1 Comparison of RMSE average value



Algorithm 1: FedLSTM-Sel 总体流程



plaintext



```plaintext
输入：客户端集合C，窗口大小W，历史精度序列H_i，通信延迟记录T_i，评分参数α, β, λ，延迟调节因子δ  
输出：每轮训练的客户端选择集C_selected  
1: 初始化全局模型，并广播至所有客户端。  
2: 对每个训练窗口循环执行：  
   2.1 窗口内数据观测阶段（连续W轮）：  
      对于每一轮t：所有客户端使用本地数据进行训练，上传模型更新；  
      记录训练精度Acc^t_i，通信延迟T^t_comm_i，并加入序列H_i。  
   2.2 冻结客户端集合，进行性能预测与评分计算：  
      对于每个客户端i：  
         a. 计算平均效用：U_i = α·mean(Acc^1_i,...,Acc^W_i) + (1-α)·Var(Acc^1_i,...,Acc^W_i)·β  
         b. 输入H_i到LSTM模型，预测下一轮精度Acc^ˆ_i；  
         c. 计算通信延迟调节因子γ_i（根据T^t_comm_i与阈值T_thr的比较）；  
         d. 综合评分：S'_i = S_i·γ_i  
   2.3 选择评分最高的前N个客户端组成C_selected  
   2.4 广播更新后的全局模型至C_selected，进入下一轮训练。  
```

### 1.2 预测模型与自适应观察窗口

#### 1.2.1 预测模型

FedLSTM-Sel 通过双层 LSTM 网络建模客户端性能的时间依赖关系，输入为长度 k 的历史精度序列，输出为预测精度 \(\hat{\text{Acc}}_i\)。模型结构如下：



- **输入层**：接收序列 \([\text{Acc}^{t-k+1}_i, \dots, \text{Acc}^t_i]\)，维度为 k；
- **LSTM 层**：两层 128 维隐藏单元，捕捉长期依赖；
- **输出层**：全连接层映射至预测值，损失函数为均方误差（MSE）。



模型设计能有效捕捉训练趋势，避免引入延迟和多样性等弱相关变量，保持模型简洁性和部署友好性。输入序列仅使用客户端历史精度数据，无需额外信息，避免隐私泄露风险。

#### 1.2.2 自适应观察窗口

窗口大小 W 的动态调整是 FedLSTM-Sel 平衡预测精度与响应速度的关键。定义目标函数：\(W_{\text{opt}} = \argmax_W \left( \text{Corr}^W(\text{Acc}, \hat{\text{Acc}}) \cdot \frac{1}{W} \right)\) 其中，\(\text{Corr}^W(\text{Acc}, \hat{\text{Acc}})\) 为历史精度与预测精度的相关系数。算法根据当前网络状态自适应调整 W：



- **网络波动大**（如连续 W 轮延迟超过阈值）：缩小 W 至 \(\max(W/2, W_{\text{min}})\)，快速剔除异常客户端；
- **网络稳定**（如连续 W 轮延迟低于阈值）：增大 W 至 \(\min(2W, W_{\text{max}})\)，提升 LSTM 预测可靠性；
- 否则维持原窗口大小。



**Algorithm 2: 自适应窗口调整机制**

```plaintext
输入：窗口W，预测精度序列Acc^ˆ，实际精度序列Acc  
输出：新的窗口大小W_new  
1. 计算当前预测准确性指标：r = \text{Corr}(Acc_i, \hat{\text{Acc}}_i)  
2. 计算目标函数值：...（原文未明确，需补充）  
3. 判断延迟波动状态：  
   若最近W轮内通信延迟超过阈值次数 > 50%，说明网络不稳定：  
      W_new = \max(W/2, W_min)  
   若延迟连续低于阈值，说明网络稳定：  
      W_new = \min(2×W, W_max)  
   否则：  
      W_new = W  
4. 返回 W_new  
```

#### 1.2.3 冻结选择与长期调度策略

在每个窗口周期内，FedLSTM-Sel 冻结客户端集合，通过累积性能数据评估其长期表现。服务器记录训练耗时、通信延迟和每轮训练精度，计算长期平均效用：\(\overline{U}^{\text{long}}_i = \frac{1}{W} \sum_{t=1}^W \left( \alpha \cdot \text{Acc}^t_i + (1-\alpha) \cdot \text{Var}(\text{Acc}^{1:t}_i) \cdot \beta \right)\) 冻结机制减少了短期性能波动对策略决策的干扰，提升了系统鲁棒性。在下一窗口中，服务器根据历史累计效用和预测结果重新排序客户端，实现更加稳健的调度策略。

## 2 实验结果

### 2.1 实验设置

- 数据集

  ：

  - MNIST：100 个客户端，Dirichlet 分布（α∈{0.1, 0.5, 2}）；
  - CIFAR-10：200 个客户端，Dirichlet 分布（α∈{0.1, 0.5, 2}）；
  - EMNIST：500 个客户端，α=0.2（高异构场景）。

- 模型配置

  ：

  - MNIST：两层 CNN，基线准确率 98%（IID）；
  - CIFAR-10：ResNet-18，基线准确率 75%（IID）。

- **通信异构性**：模拟带宽 10 kbps–10 Mbps，30% 客户端为高延迟设备。

- **训练参数**：本地训练 5 轮 / 全局轮次，共 50 轮，评估指标包括准确率、通信成本、收敛速度。

### 2.2 MNIST 上的训练性能与通信效率

在 MNIST（α=0.5）场景下，图 2 展示了不同策略的准确率随轮数变化情况：



- FedLSTM-Sel 在第 8 轮达到 90% 准确率，比随机选择提前 4 轮，最终准确率 95.2%（+7.2% vs 随机选择）。
- 通信成本：FedLSTM-Sel 总传输量 32 MB，较随机选择（68 MB）减少 52%（图 3）。



**表 1 RMSE 平均比较** Tab.1 Comparison of RMSE average value



| 算法     | X 轴位置平均 RMSE (m) | Y 轴位置平均 RMSE (m) | X 轴速度平均 RMSE (m/s) | Y 轴速度平均 RMSE (m/s) |
| -------- | --------------------- | --------------------- | ----------------------- | ----------------------- |
| S-IMM5   | 12.4938               | 14.0908               | 2.3273                  | 2.7796                  |
| SD-VSMM  | 10.0366               | 8.9900                | 3.0303                  | 2.9274                  |
| SA-VSMM  | 8.7902                | 11.2237               | 3.1351                  | 3.7196                  |
| SCD-VSMM | 6.1403                | 6.2550                | 3.9425                  | 3.9223                  |

### 2.3 非 IID 情况下的鲁棒性分析

在极端非 IID 场景（α=0.1）下：



- FedLSTM-Sel 准确率 85.7%，比随机选择（72.3%）提升 13.4%，优于性能优先（79.1%）和多样性优先（81.3%）。
- 多样性感知机制有效抑制 “强者愈强” 偏差（图 4）。

### 2.4 CIFAR-10 上的性能表现

- **中度异构（α=0.3）**：FedLSTM-Sel 在 35 轮达到 75.0% 准确率，较基线快 15 轮（图 5 (a)）。
- **极端异构（α=0.1）**：准确率 68.2%，显著高于其他策略（图 5 (b)）。
- 通信成本降低 40%，验证复杂模型下的效率优势。

### 2.5 EMNIST 场景下的大规模测试

在 500 客户端、α=0.2 场景下：



- FedLSTM-Sel 在 45 轮收敛至 82.1% 准确率，随机选择仅 71.5%（图 6）。
- 自适应窗口机制动态调整选择节奏，提升高异构场景稳定性。

### 2.6 模块消融实验

图 7 展示关键模块移除后的影响：



- 移除多样性因子：准确率下降 3–5%；
- 移除性能因子：收敛速度变慢 20%；
- 移除 LSTM 预测：收敛轮次增加 15%。 结果表明各模块对系统性能均有不可替代性。

## 3 结束语

本文提出融合客户端历史性能与数据多样性的混合客户端选择策略，引入 LSTM 预测模型，实现更精准的选择决策。实验结果表明，与传统方法相比，该方法在模型精度、收敛速度和通信效率上均有显著提升。在非 IID 环境中展现出优越的鲁棒性，为资源受限的联邦学习场景提供了有效的解决方案。